{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wv9q_pcGshE"
      },
      "source": [
        "# Assignment 2 2AMM10 2023-2024\n",
        "\n",
        "## Group: [Fill in your group name]\n",
        "### Member 1: [Fill in your name]\n",
        "### Member 2: [Fill in your name]\n",
        "### Member 3: [Fill in your name]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQzvuDWw_Eyw"
      },
      "source": [
        "We need to install some specific libraries. The cell below installs torch_geometric for torch 2.6.0+cu124. In case the current version of torch is different, check [here](https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html) to see which versions (of both libraries) you should install. You might also need to install an old version of torch from [here](https://pytorch.org/get-started/previous-versions/)\n",
        "\n",
        "**Note:** Do not install pyg_lib from the optional dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ibC2lMHfD67H"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: torch\n",
            "Version: 2.6.0\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3-Clause\n",
            "Location: C:\\Users\\20182672\\AppData\\Local\\anaconda3\\envs\\MLEngineering\\Lib\\site-packages\n",
            "Requires: filelock, fsspec, jinja2, networkx, setuptools, sympy, typing-extensions\n",
            "Required-by: accelerate, flair, openml-pytorch, pytorch-lightning, pytorch_revgrad, torchmetrics, torchvision, transformer-smaller-training-vocab\n"
          ]
        }
      ],
      "source": [
        "!pip show torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8qrPQFNe_AJu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rdkit in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (2025.3.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from rdkit) (1.26.4)\n",
            "Requirement already satisfied: Pillow in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from rdkit) (10.4.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch_geometric in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from torch_geometric) (3.11.14)\n",
            "Requirement already satisfied: fsspec in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from torch_geometric) (7.0.0)\n",
            "Requirement already satisfied: pyparsing in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from aiohttp->torch_geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from aiohttp->torch_geometric) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from aiohttp->torch_geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from requests->torch_geometric) (2025.4.26)\n",
            "Requirement already satisfied: colorama in c:\\users\\20182672\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->torch_geometric) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Requirement already satisfied: torch_scatter in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (2.1.2+pt26cu124)\n",
            "Requirement already satisfied: torch_sparse in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (0.6.18+pt26cu124)\n",
            "Requirement already satisfied: torch_cluster in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (1.6.3+pt26cu124)\n",
            "Requirement already satisfied: torch_spline_conv in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (1.2.2+pt26cu124)\n",
            "Requirement already satisfied: scipy in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from torch_sparse) (1.15.2)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from scipy->torch_sparse) (1.26.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit\n",
        "!pip install torch_geometric\n",
        "!pip install torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.6.0+cu124.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "WVL2eo0g_Iuv"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw, AllChem\n",
        "from rdkit import RDLogger\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from rdkit import Chem\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "H8rvaK56_iQ7"
      },
      "outputs": [],
      "source": [
        "with open('pos_data.pkl', 'rb') as f:\n",
        "    pos_data = pickle.load(f)\n",
        "\n",
        "with open('type_data.pkl', 'rb') as f:\n",
        "    type_data = pickle.load(f)\n",
        "\n",
        "with open('smiles.pkl', 'rb') as f:\n",
        "    smiles_data = pickle.load(f)\n",
        "\n",
        "data_split = np.load('data_split.npz')\n",
        "\n",
        "train_idxes = data_split['train_idx']\n",
        "test_idxes = data_split['test_idx']\n",
        "\n",
        "formation_energy = np.load('formation_energy.npz')\n",
        "\n",
        "fe = formation_energy['y'] # normalized formation energy\n",
        "mu = formation_energy['mu']\n",
        "std = formation_energy['sigma']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DIsGRQcxA_4Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of data\n",
            "pos_data: 129012, type_data: 129012, smiles: 129012\n",
            "Idxes\n",
            "train: 119012, test: 10000, sum: 129012\n"
          ]
        }
      ],
      "source": [
        "# shapes of lists\n",
        "print(\"Length of data\")\n",
        "print(f\"pos_data: {len(pos_data)}, type_data: {len(type_data)}, smiles: {len(smiles_data)}\")\n",
        "print(\"Idxes\")\n",
        "print(f\"train: {len(train_idxes)}, test: {len(test_idxes)}, sum: {len(train_idxes) + len(test_idxes)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "bVDJF7I3BFa2"
      },
      "outputs": [],
      "source": [
        "def at_number_to_atom_name(at_number):\n",
        "    if at_number == 6:\n",
        "        return 'C'\n",
        "    elif at_number == 1:\n",
        "        return 'H'\n",
        "    elif at_number == 7:\n",
        "        return 'N'\n",
        "    elif at_number == 8:\n",
        "        return 'O'\n",
        "    elif at_number == 9:\n",
        "        return 'F'\n",
        "    elif at_number == 16:\n",
        "        return 'S'\n",
        "    else:\n",
        "        return 'Unknown'\n",
        "\n",
        "def inspect_structure(idx):\n",
        "    smile = smiles_data[idx]\n",
        "    pos = pos_data[idx]\n",
        "    typ = type_data[idx]\n",
        "\n",
        "    header = f\"{'Atom':^5}│{'Number':^6}│{'x':^10}│{'y':^10}│{'z':^10}\"\n",
        "    line   = \"─────┼──────┼──────────┼──────────┼──────────\"\n",
        "    print(header)\n",
        "    print(line)\n",
        "\n",
        "    for atom_num, (x, y, z) in zip(typ, pos):\n",
        "        atom_sym = at_number_to_atom_name(atom_num)\n",
        "        print(f\"{atom_sym:^5}│{atom_num:^6}│{x:>10.3f}│{y:>10.3f}│{z:>10.3f}\")\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "    print(f'SMILE: {smile}')\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "    print(f'Formation Energy: {fe[idx]*std + mu:.3f}')\n",
        "    print(f'Formation Energy (normalized): {fe[idx]:.5f}')\n",
        "    mol = Chem.MolFromSmiles(smile)\n",
        "    if mol:\n",
        "        # RDKit prefers 2‑D coordinates for nice depictions\n",
        "        Chem.AllChem.Compute2DCoords(mol)\n",
        "        img = Draw.MolToImage(mol, size=(300, 300))\n",
        "\n",
        "        # Display with matplotlib (works both in notebooks and scripts)\n",
        "        plt.figure(figsize=(3, 3))\n",
        "        plt.axis('off')\n",
        "        plt.imshow(img)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "K1rs7hhCC4oq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Atom │Number│    x     │    y     │    z     \n",
            "─────┼──────┼──────────┼──────────┼──────────\n",
            "  C  │  6   │    -0.013│     1.086│     0.008\n",
            "  H  │  1   │     0.002│    -0.006│     0.002\n",
            "  H  │  1   │     1.012│     1.464│     0.000\n",
            "  H  │  1   │    -0.541│     1.447│    -0.877\n",
            "  H  │  1   │    -0.524│     1.438│     0.906\n",
            "\n",
            "\n",
            "SMILE: C\n",
            "\n",
            "\n",
            "Formation Energy: -17.172\n",
            "Formation Energy (normalized): 5.72327\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD7CAYAAABDsImYAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAACf9JREFUeJzt3EtsVGUDxvHnzNDpUFpoKU1TSpWLt8hFo9wMaQLeIisXLDAxMUYjMZGF4AJdyQJjDEKaSFIWhMCGBCOJgBJQQ6IRFkYXSg0Gk4KiJdrCVEaGMkPndUE64QvIN8Whc+D5/zYk9EzPezr5z7m9c6IQQhCAO1qi2gMAcOsROmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AED46o9AJSnUChoYGBAf//9ty5fvqz6+no1Njaqvr5eURRds3wIQfl8XsViUVEUKZVKKZEo73P90qVLKhaLkqRUKqVkMlnRbcHYi0IIodqDwLVG3pbTp09r7969OnLkiPr6+jQ0NKTh4WGl02lNnjxZCxYs0IoVK/Tggw9KUin6gYEBvffee+rp6dHUqVO1Zs0azZkzp6x1r127VsePH1c6ndaGDRs0e/bsW7ORGDsBsVMsFsNff/0VNm/eHDo6OkJtbW2IoihIClEUhUQiESQFSSGVSoWWlpbw7rvvhkwmE4rFYgghhNOnT4fOzs4gKdxzzz3hyy+/LHv9jz32WJAUJkyYEL766qtbtZkYQxy6x0wIQWfOnNE777yj7du3a2hoSMlkUrNmzdJ9992nlpYWpdNpZTIZnTp1SsePH1d/f782bNigTCajt956S42NjdXeDMQMocfM0NCQtm3bpp07d2poaEgNDQ1auXKlnn/+ec2bN09NTU2Srpyz9/b26vDhw9q4caP6+vrU39+vQqFQ5S1AHBF6jIQQdOzYMXV1denChQuqqanRq6++WtpLX33RLZVK6YEHHtDMmTM1Z84cHTx4UKtXr1Zzc3MVtwBxRegxEkJQd3e3MpmMJGnRokV6++23VVdXd90r69KV4Ds7O9XZ2SlJ/7ocvBF6jAwMDOizzz6TJCUSCb3++us3jHwEceP/YcJMjPzwww86f/68JGnWrFl69NFHqzwi3CnYo8fI999/r3w+L0maPXu2GhoaKra3DiGUJsHAD6HHSH9/fynGadOmqba2tiK/N5PJaPfu3frmm2/KWr6vr68i60V8EHqMnD9/vjQjrr6+vmJTT8+ePavu7u6K/C7cngg9RorFYin0cuellyOZTGrixIlKpVJlLX/u3Dnux99hCD1GGhoalEgkVCwWdeHChYqdU3d0dGjTpk1atGhRWcs/++yz+u677yqybsQDocdIU1NTaU9eyVlu48aN05QpU9Te3l7W8uXu+XH74PZajNx///0aN+7KZ++JEyeUy+VKh/LAf0HoMfLII49o/PjxkqRjx47p5MmTVR4R7hSEHiMdHR2aP3++pCsPf9i2bZuGh4erPCrcCQg9RpLJpF555ZXSefrHH3+sTz75RCGEGx7Cj/y8mof5V4+h2mPBtbgYFzOPP/64nnvuOe3evVuDg4Nas2aNstmsnnnmGTU3N//PbbcQgnK5nP7880+dOHFC8+bNU1tb25iPOYSgH3/8Ud9++62Gh4fV2tqqJ598Uul0eszHgusj9BiJokiNjY1644039Ntvv+nIkSM6deqUXnvtNT399NNatmyZpk2bprq6OuXzef3xxx/q6enR4cOH9fvvv+uDDz7QypUrx/xLLmfOnNG6dev0+eefK4SghQsXavHixYQeI4QeM1EU6aGHHlJXV5fWr1+v/fv3K5vNas+ePdq3b5+ampqUTqdVKBQ0ODioixcvSrpyS+znn39WoVAY09tj+XxeH374ob7++mstX75cR48eHbN1o3yco8dQMpnUww8/rB07dmjXrl1aunSpWltbNX78eOVyOZ09e1bZbFa1tbVqbW3V8uXLtWPHDq1evVo1NTWSrsysmzhxopqbm9XU1FT6/3JMmjRJzc3Nmjx58g1fN/KgjK1bt6q9vV3r1q0r3R5EvPAU2JgbubD166+/6qefftK5c+d06dIl1dfXq62tTffee69aWlpKh+sj/xYKBfX19SmXyymVSqmtrU11dXVlrfOXX35RLpdTIpFQR0fHv74um83qpZde0hdffKHu7m7Nnz9fnZ2dmjlzpvbu3aspU6ZU5o+A/4yP35iLokhRFGn69OmaPn162a+rqanR3XfffVPrLPd1H330kQ4cOKAVK1boiSeeUDabvan14dbj0B2jFkJQT0+PNm3apKlTp2rVqlXsvWOO0DFqg4OD6urqUm9vr15++WUtWbKEx1nFHKFjVIaHh3Xo0CHt27dPCxYs0KpVq4j8NsA5OkZlYGBA77//vgqFgt58801NmjSpNE336q/VFotFFYvFin6vHjePq+4Yla6uLq1du1aSlE6nr5mpd/HiRUVRpAkTJuiFF17Qli1bqjVUXIU9OkZlxowZevHFF6/7s2w2q08//VQNDQ166qmnSl/QQfWxR8eoXL58+V+ffHPy5EktXbpUM2bM0J49e9TS0sIEmpjgXcCo3CjckVl0URSppqaGyGOEdwIVk0qlNHfuXLW3txN5zHDojorJ5/Pq7e1VKpXSXXfdRewxQuiAAW5yAgYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTBA6ICBfwC9hRQTICOM3AAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# methane\n",
        "# Note how methane has a relatively high formation energy (compared to QM9)\n",
        "# This correlates with lower thermodynamic stability and higher reactivity\n",
        "# For example, methane readily burns in oxygen (CH₄ + 2O₂ → CO₂ + 2H₂O)\n",
        "inspect_structure(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "vo8hYLuQCeBR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Atom │Number│    x     │    y     │    z     \n",
            "─────┼──────┼──────────┼──────────┼──────────\n",
            "  C  │  6   │    -0.034│     1.335│     0.058\n",
            "  O  │  8   │    -0.001│    -0.079│     0.010\n",
            "  C  │  6   │     0.633│    -0.582│    -1.107\n",
            "  C  │  6   │     0.016│    -0.475│    -2.538\n",
            "  C  │  6   │     0.749│    -1.790│    -2.803\n",
            "  C  │  6   │     0.822│    -2.132│    -1.324\n",
            "  C  │  6   │     2.085│    -1.746│    -2.033\n",
            "  O  │  8   │     3.126│    -2.601│    -2.329\n",
            "  C  │  6   │     2.171│    -0.389│    -1.336\n",
            "  H  │  1   │     0.978│     1.764│     0.077\n",
            "  H  │  1   │    -0.577│     1.759│    -0.799\n",
            "  H  │  1   │    -0.553│     1.611│     0.978\n",
            "  H  │  1   │    -1.068│    -0.621│    -2.507\n",
            "  H  │  1   │     0.263│     0.403│    -3.145\n",
            "  H  │  1   │     0.616│    -2.488│    -3.619\n",
            "  H  │  1   │     0.527│    -3.001│    -0.757\n",
            "  H  │  1   │     3.513│    -2.329│    -3.169\n",
            "  H  │  1   │     2.508│     0.486│    -1.904\n",
            "  H  │  1   │     2.716│    -0.470│    -0.392\n",
            "\n",
            "\n",
            "SMILE: CO[C@]12C[C@@H]3[C@H]1[C@]3(O)C2\n",
            "\n",
            "\n",
            "Formation Energy: -78.882\n",
            "Formation Energy (normalized): -0.26165\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# random structure\n",
        "inspect_structure(np.random.choice(range(len(smiles_data))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The available device is cpu\n"
          ]
        }
      ],
      "source": [
        "# Check device settings\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "\n",
        "print(f'The available device is {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76MeHNQ_Gd9t"
      },
      "source": [
        "## Task 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PART II: SMILES\n",
        "- String sequence to continous values\n",
        "- Permutational invariance should be taken into account with canonical SMILES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lv736iffCez4"
      },
      "outputs": [],
      "source": [
        "# Tokenize the SMILES strings\n",
        "# https://jcheminf.biomedcentral.com/articles/10.1186/s13321-023-00725-9\n",
        "# Unclear to me whether we want to encode to values, but seems logical\n",
        "class SMILESAISTokenizer:\n",
        "    def __init__(self):\n",
        "        self.vocab = set()\n",
        "        self.special_tokens = ['<PAD>', '<START>', '<END>', '<UNK>']\n",
        "        self.token_to_idx = {}\n",
        "        self.idx_to_token = {}\n",
        "    \n",
        "    def build_vocabulary(self, smiles_list):\n",
        "        tokens = set()\n",
        "\n",
        "        for smi in smiles_list:\n",
        "            tokens.update(self.tokenize(smi))\n",
        "\n",
        "        tokens = sorted(list(tokens))\n",
        "        full_vocab = self.special_tokens + tokens\n",
        "        self.vocab = full_vocab\n",
        "        self.token_to_idx = {tok: i for i, tok in enumerate(full_vocab)}\n",
        "        self.idx_to_token = {i: tok for tok, i in self.token_to_idx.items()}\n",
        "\n",
        "        return full_vocab\n",
        "    \n",
        "    def tokenize(self, smiles):\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is None:\n",
        "            return []\n",
        "\n",
        "        tokens = []\n",
        "        for atom in mol.GetAtoms():\n",
        "            symbol = atom.GetSymbol()\n",
        "            if atom.GetIsAromatic():\n",
        "                symbol = symbol.lower()\n",
        "\n",
        "            charge = atom.GetFormalCharge()\n",
        "            chiral = str(atom.GetChiralTag())\n",
        "            hs = atom.GetTotalNumHs()\n",
        "            ring = 'R' if atom.IsInRing() else '!R'\n",
        "            neighbors = sorted([nbr.GetSymbol() for nbr in atom.GetNeighbors()])\n",
        "\n",
        "            token = f\"{symbol}:{charge}:{chiral}:{hs}:{ring}:[{','.join(neighbors)}]\"\n",
        "            tokens.append(token)\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def encode(self, smiles, max_length=None):\n",
        "        tokens = self.tokenize(smiles)\n",
        "        encoded = [self.token_to_idx.get(tok, self.token_to_idx['<UNK>']) for tok in tokens]\n",
        "\n",
        "        if max_length:\n",
        "            encoded = encoded[:max_length]\n",
        "            encoded += [self.token_to_idx['<PAD>']] * (max_length - len(encoded))\n",
        "        return encoded\n",
        "\n",
        "    def decode(self, indices):\n",
        "        tokens = [self.idx_to_token.get(idx, '<UNK>') for idx in indices]\n",
        "        tokens = [tok for tok in tokens if tok not in self.special_tokens]\n",
        "        return tokens # Not sure whether we need decoder\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 12\n",
            "Encoded: [6, 5, 10, 0, 0, 0, 0, 0, 0, 0]\n",
            "Decoded tokens: ['C:0:CHI_UNSPECIFIED:3:!R:[C]', 'C:0:CHI_UNSPECIFIED:2:!R:[C,O]', 'O:0:CHI_UNSPECIFIED:1:!R:[C]']\n"
          ]
        }
      ],
      "source": [
        "# # TOY TEST\n",
        "# smiles_list = [\n",
        "#     \"CCO\",         # ethanol\n",
        "#     \"c1ccccc1\",    # benzene\n",
        "#     \"C[N+](C)(C)C\",# tetramethylammonium\n",
        "#     \"O=C=O\"        # carbon dioxide\n",
        "# ]\n",
        "\n",
        "# tokenizer = SMILESAISTokenizer()\n",
        "# # Initialize and build vocab\n",
        "# vocab = tokenizer.build_vocabulary(smiles_list)\n",
        "# print(\"Vocabulary size:\", len(vocab))\n",
        "\n",
        "# # Tokenize and encode a molecule\n",
        "# encoded = tokenizer.encode(\"CCO\", max_length=10)\n",
        "# print(\"Encoded:\", encoded)\n",
        "# print(\"Decoded tokens:\", tokenizer.decode(encoded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SMILESDataset(Dataset):\n",
        "    def __init__(self, tokenizer, smiles_list, augment=True):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.smiles = smiles_list\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.smiles)\n",
        "\n",
        "    def randomize_smiles(self, mol):\n",
        "        return Chem.MolToSmiles(mol, doRandom=True)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        smiles = self.smiles[idx]\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is None:\n",
        "            return self.__getitem__((idx + 1) % len(self.smiles))  # fallback\n",
        "\n",
        "        if self.augment:\n",
        "            smiles = self.randomize_smiles(mol)\n",
        "        else:\n",
        "            smiles = Chem.MolToSmiles(mol, canonical=True)\n",
        "\n",
        "        encoded = self.tokenizer.encode([smiles])[0]\n",
        "        return torch.tensor(encoded, dtype=torch.long)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create tokenzier and dataset\n",
        "tokenizer = SMILESAISTokenizer()\n",
        "tokenizer.build_vocabulary(smiles_data)\n",
        "\n",
        "# Split data into train and validation 80/20, already having a test dataset\n",
        "train_data = [smiles_data[i] for i in train_idxes[:-int(0.2 * len(train_idxes))]] # select first 80% of train_idxes\n",
        "val_data = [smiles_data[i] for i in train_idxes[-int(0.2 * len(train_idxes)):]] # select last 20% of train_idxes\n",
        "test_data = [smiles_data[i] for i in test_idxes]\n",
        "\n",
        "train_dataset = SMILESDataset(tokenizer, train_data, augment=True)\n",
        "val_dataset = SMILESDataset(tokenizer, val_data, augment=False)\n",
        "test_dataset = SMILESDataset(tokenizer, test_data, augment=False)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transformer block\n",
        "# https://pubs.rsc.org/en/content/articlelanding/2022/dd/d2dd00058j\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.attention = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
        "        self.layer_norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(embed_dim, ff_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(ff_dim, embed_dim)\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Multi-head attention with residual connection\n",
        "        attn_output, _ = self.attention(x, x, x)\n",
        "        x = self.layer_norm1(x + self.dropout(attn_output))\n",
        "\n",
        "        # Feed-forward network with residual connection\n",
        "        mlp_output = self.mlp(x)\n",
        "        x = self.layer_norm2(x + self.dropout(mlp_output))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, embed_dim, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, embed_dim)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * (-torch.log(torch.tensor(10000.0)) / embed_dim))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_heads, ff_dim, num_layers, max_len, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.positional_encoding = PositionalEncoding(embed_dim, max_len)\n",
        "        self.transformer_blocks = nn.ModuleList([\n",
        "            TransformerBlock(embed_dim, num_heads, ff_dim, dropout) for _ in range(num_layers)\n",
        "        ])\n",
        "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
        "        self.regression_head = nn.Sequential(\n",
        "            nn.Linear(embed_dim, embed_dim // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(embed_dim // 2, 1)  # Output a single value\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input embedding + positional encoding\n",
        "        x = self.embedding(x)\n",
        "        x = self.positional_encoding(x)\n",
        "\n",
        "        # Pass through Transformer blocks\n",
        "        for block in self.transformer_blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        # Apply LayerNorm and regression head\n",
        "        x = self.layer_norm(x)\n",
        "        x = x.mean(dim=1)  # Global pooling (mean over sequence length)\n",
        "        x = self.regression_head(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 1])\n"
          ]
        }
      ],
      "source": [
        "# Inital guess for parameters\n",
        "vocab_size = len(tokenizer.vocab)  # Vocabulary size from tokenizer\n",
        "embed_dim = 128  # Embedding dimension\n",
        "num_heads = 4  # Number of attention heads\n",
        "ff_dim = 256  # Feed-forward network dimension\n",
        "num_layers = 6  # Number of Transformer layers\n",
        "max_len = 100  # Maximum sequence length\n",
        "\n",
        "model = TransformerDecoder(vocab_size, embed_dim, num_heads, ff_dim, num_layers, max_len)\n",
        "\n",
        "# Example input (batch of tokenized SMILES)\n",
        "input_tokens = torch.randint(0, vocab_size, (32, max_len))  # Batch of 32 sequences\n",
        "output = model(input_tokens)  # Output shape: (32, 1)\n",
        "print(output.shape)  # Should be [32, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code to train the model \n",
        "def train_model(model, train_loader, val_loader, num_epochs=10, learning_rate=1e-3):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    \n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            batch = batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch)\n",
        "            loss = criterion(outputs.squeeze(), fe[train_idxes[:-int(0.2 * len(train_idxes))]].to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # Validation step\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                batch = batch.to(device)\n",
        "                outputs = model(batch)\n",
        "                loss = criterion(outputs.squeeze(), fe[train_idxes[-int(0.2 * len(train_idxes)):]].to(device))\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        print(f\"Validation Loss: {avg_val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "train_model(model, train_loader, val_loader, num_epochs=10, learning_rate=1e-3)\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'transformer_decoder.pth')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0zvKnpLGf9v"
      },
      "source": [
        "## Task 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AC1KICrZGgkY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mIuOY4BGxqU"
      },
      "source": [
        "## Task 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "z_NgxsO3GxEE"
      },
      "outputs": [],
      "source": [
        "def is_valid_smiles(smiles):\n",
        "    if smiles is None:\n",
        "        return False\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        return mol is not None\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "def canonicalize(smiles):\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol:\n",
        "            return Chem.MolToSmiles(mol, canonical=True)\n",
        "        return 'None'\n",
        "    except:\n",
        "        return 'None'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "SN_jGgOwG4kK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('COO', 'COO')"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "canonicalize(\"COO\"), canonicalize(\"O(C)O\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "-bhjYhYrHCuQ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(True, True, False)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "is_valid_smiles(\"COO\"), is_valid_smiles(\"O(C)O\"), is_valid_smiles(\"C##\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_YgzDpMH-Vl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "MLEngineering",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
