{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wv9q_pcGshE"
      },
      "source": [
        "# Assignment 2 2AMM10 2023-2024\n",
        "\n",
        "## Group: [Fill in your group name]\n",
        "### Member 1: [Fill in your name]\n",
        "### Member 2: [Fill in your name]\n",
        "### Member 3: [Fill in your name]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQzvuDWw_Eyw"
      },
      "source": [
        "We need to install some specific libraries. The cell below installs torch_geometric for torch 2.6.0+cu124. In case the current version of torch is different, check [here](https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html) to see which versions (of both libraries) you should install. You might also need to install an old version of torch from [here](https://pytorch.org/get-started/previous-versions/)\n",
        "\n",
        "**Note:** Do not install pyg_lib from the optional dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ibC2lMHfD67H"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: torch\n",
            "Version: 2.6.0\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3-Clause\n",
            "Location: C:\\Users\\20182672\\AppData\\Local\\anaconda3\\envs\\MLEngineering\\Lib\\site-packages\n",
            "Requires: filelock, fsspec, jinja2, networkx, setuptools, sympy, typing-extensions\n",
            "Required-by: accelerate, flair, openml-pytorch, pytorch-lightning, pytorch_revgrad, torchmetrics, torchvision, transformer-smaller-training-vocab\n"
          ]
        }
      ],
      "source": [
        "!pip show torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8qrPQFNe_AJu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rdkit in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (2025.3.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from rdkit) (1.26.4)\n",
            "Requirement already satisfied: Pillow in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from rdkit) (10.4.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch_geometric in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from torch_geometric) (3.11.14)\n",
            "Requirement already satisfied: fsspec in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from torch_geometric) (7.0.0)\n",
            "Requirement already satisfied: pyparsing in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from aiohttp->torch_geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from aiohttp->torch_geometric) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from aiohttp->torch_geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from requests->torch_geometric) (2025.4.26)\n",
            "Requirement already satisfied: colorama in c:\\users\\20182672\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->torch_geometric) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Requirement already satisfied: torch_scatter in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (2.1.2+pt26cu124)\n",
            "Requirement already satisfied: torch_sparse in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (0.6.18+pt26cu124)\n",
            "Requirement already satisfied: torch_cluster in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (1.6.3+pt26cu124)\n",
            "Requirement already satisfied: torch_spline_conv in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (1.2.2+pt26cu124)\n",
            "Requirement already satisfied: scipy in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from torch_sparse) (1.15.2)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in c:\\users\\20182672\\appdata\\local\\anaconda3\\envs\\mlengineering\\lib\\site-packages (from scipy->torch_sparse) (1.26.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit\n",
        "!pip install torch_geometric\n",
        "!pip install torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.6.0+cu124.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVL2eo0g_Iuv"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw, AllChem\n",
        "from rdkit import RDLogger\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from rdkit import Chem\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "H8rvaK56_iQ7"
      },
      "outputs": [],
      "source": [
        "with open('pos_data.pkl', 'rb') as f:\n",
        "    pos_data = pickle.load(f)\n",
        "\n",
        "with open('type_data.pkl', 'rb') as f:\n",
        "    type_data = pickle.load(f)\n",
        "\n",
        "with open('smiles.pkl', 'rb') as f:\n",
        "    smiles_data = pickle.load(f)\n",
        "\n",
        "data_split = np.load('data_split.npz')\n",
        "\n",
        "train_idxes = data_split['train_idx']\n",
        "test_idxes = data_split['test_idx']\n",
        "\n",
        "formation_energy = np.load('formation_energy.npz')\n",
        "\n",
        "fe = formation_energy['y'] # normalized formation energy\n",
        "mu = formation_energy['mu']\n",
        "std = formation_energy['sigma']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DIsGRQcxA_4Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of data\n",
            "pos_data: 129012, type_data: 129012, smiles: 129012\n",
            "Idxes\n",
            "train: 119012, test: 10000, sum: 129012\n"
          ]
        }
      ],
      "source": [
        "# shapes of lists\n",
        "print(\"Length of data\")\n",
        "print(f\"pos_data: {len(pos_data)}, type_data: {len(type_data)}, smiles: {len(smiles_data)}\")\n",
        "print(\"Idxes\")\n",
        "print(f\"train: {len(train_idxes)}, test: {len(test_idxes)}, sum: {len(train_idxes) + len(test_idxes)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean of formation energy: 0.0004583929\n",
            "Standard deviation of formation energy: 1.0020696\n",
            "Maximum formation energy: 6.492535\n",
            "Minimum formation energy: -3.5815375\n"
          ]
        }
      ],
      "source": [
        "# Check distribution of formation energy\n",
        "plt.hist(fe, bins=50, density=True)\n",
        "plt.xlabel('Normalized Formation Energy')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Distribution of Normalized Formation Energy')\n",
        "plt.show()\n",
        "\n",
        "print(\"Mean of formation energy:\", np.mean(fe))\n",
        "print(\"Standard deviation of formation energy:\", np.std(fe))\n",
        "print(\"Maximum formation energy:\", np.max(fe))\n",
        "print(\"Minimum formation energy:\", np.min(fe))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bVDJF7I3BFa2"
      },
      "outputs": [],
      "source": [
        "def at_number_to_atom_name(at_number):\n",
        "    if at_number == 6:\n",
        "        return 'C'\n",
        "    elif at_number == 1:\n",
        "        return 'H'\n",
        "    elif at_number == 7:\n",
        "        return 'N'\n",
        "    elif at_number == 8:\n",
        "        return 'O'\n",
        "    elif at_number == 9:\n",
        "        return 'F'\n",
        "    elif at_number == 16:\n",
        "        return 'S'\n",
        "    else:\n",
        "        return 'Unknown'\n",
        "\n",
        "def inspect_structure(idx):\n",
        "    smile = smiles_data[idx]\n",
        "    pos = pos_data[idx]\n",
        "    typ = type_data[idx]\n",
        "\n",
        "    header = f\"{'Atom':^5}│{'Number':^6}│{'x':^10}│{'y':^10}│{'z':^10}\"\n",
        "    line   = \"─────┼──────┼──────────┼──────────┼──────────\"\n",
        "    print(header)\n",
        "    print(line)\n",
        "\n",
        "    for atom_num, (x, y, z) in zip(typ, pos):\n",
        "        atom_sym = at_number_to_atom_name(atom_num)\n",
        "        print(f\"{atom_sym:^5}│{atom_num:^6}│{x:>10.3f}│{y:>10.3f}│{z:>10.3f}\")\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "    print(f'SMILE: {smile}')\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "    print(f'Formation Energy: {fe[idx]*std + mu:.3f}')\n",
        "    print(f'Formation Energy (normalized): {fe[idx]:.5f}')\n",
        "    mol = Chem.MolFromSmiles(smile)\n",
        "    if mol:\n",
        "        # RDKit prefers 2‑D coordinates for nice depictions\n",
        "        Chem.AllChem.Compute2DCoords(mol)\n",
        "        img = Draw.MolToImage(mol, size=(300, 300))\n",
        "\n",
        "        # Display with matplotlib (works both in notebooks and scripts)\n",
        "        plt.figure(figsize=(3, 3))\n",
        "        plt.axis('off')\n",
        "        plt.imshow(img)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "K1rs7hhCC4oq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Atom │Number│    x     │    y     │    z     \n",
            "─────┼──────┼──────────┼──────────┼──────────\n",
            "  C  │  6   │    -0.013│     1.086│     0.008\n",
            "  H  │  1   │     0.002│    -0.006│     0.002\n",
            "  H  │  1   │     1.012│     1.464│     0.000\n",
            "  H  │  1   │    -0.541│     1.447│    -0.877\n",
            "  H  │  1   │    -0.524│     1.438│     0.906\n",
            "\n",
            "\n",
            "SMILE: C\n",
            "\n",
            "\n",
            "Formation Energy: -17.172\n",
            "Formation Energy (normalized): 5.72327\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# methane\n",
        "# Note how methane has a relatively high formation energy (compared to QM9)\n",
        "# This correlates with lower thermodynamic stability and higher reactivity\n",
        "# For example, methane readily burns in oxygen (CH₄ + 2O₂ → CO₂ + 2H₂O)\n",
        "inspect_structure(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vo8hYLuQCeBR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Atom │Number│    x     │    y     │    z     \n",
            "─────┼──────┼──────────┼──────────┼──────────\n",
            "  C  │  6   │    -0.143│     1.521│     0.693\n",
            "  C  │  6   │     0.003│     0.009│     0.543\n",
            "  C  │  6   │     0.619│    -0.462│    -0.800\n",
            "  C  │  6   │     1.284│    -1.791│    -0.451\n",
            "  C  │  6   │     2.629│    -1.823│     0.182\n",
            "  C  │  6   │     3.588│    -0.659│     0.233\n",
            "  O  │  8   │     4.471│    -0.752│     1.344\n",
            "  N  │  7   │     1.408│    -1.923│     1.022\n",
            "  C  │  6   │     0.902│    -0.661│     1.609\n",
            "  H  │  1   │     0.830│     2.022│     0.609\n",
            "  H  │  1   │    -0.798│     1.937│    -0.079\n",
            "  H  │  1   │    -0.570│     1.786│     1.666\n",
            "  H  │  1   │    -0.991│    -0.449│     0.625\n",
            "  H  │  1   │    -0.142│    -0.594│    -1.573\n",
            "  H  │  1   │     1.332│     0.276│    -1.184\n",
            "  H  │  1   │     0.937│    -2.679│    -0.974\n",
            "  H  │  1   │     3.162│    -2.773│     0.153\n",
            "  H  │  1   │     4.226│    -0.685│    -0.658\n",
            "  H  │  1   │     3.069│     0.309│     0.222\n",
            "  H  │  1   │     3.936│    -0.919│     2.127\n",
            "  H  │  1   │     1.713│     0.013│     1.915\n",
            "  H  │  1   │     0.338│    -0.908│     2.513\n",
            "\n",
            "\n",
            "SMILE: C[C@H]1C[C@H]2[C@@H](CO)[N@H+]2C1\n",
            "\n",
            "\n",
            "Formation Energy: -88.273\n",
            "Formation Energy (normalized): -1.17243\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# random structure\n",
        "inspect_structure(np.random.choice(range(len(smiles_data))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The available device is cpu\n"
          ]
        }
      ],
      "source": [
        "# Check device settings\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "\n",
        "print(f'The available device is {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of SMILES data: 129012\n",
            "First 10 SMILES strings:\n",
            "0: C\n",
            "1: N\n",
            "2: O\n",
            "3: C#C\n",
            "4: C#N\n",
            "5: C=O\n",
            "6: CC\n",
            "7: CO\n",
            "8: C#CC\n",
            "9: CC#N\n",
            "Max length of SMILES strings: 62\n"
          ]
        }
      ],
      "source": [
        "# These are some print statements inserted by me to check the data\n",
        "\n",
        "# Check the length of the SMILES representation\n",
        "print(f'Length of SMILES data: {len(smiles_data)}')\n",
        "# Check the first 10 SMILES strings\n",
        "print(\"First 10 SMILES strings:\")\n",
        "for i in range(10):\n",
        "    print(f\"{i}: {smiles_data[i]}\")\n",
        "# Check max lenght of SMILES strings\n",
        "max_smiles_length = max(len(smile) for smile in smiles_data) # suggestion for max lenght in model\n",
        "print(f'Max length of SMILES strings: {max_smiles_length}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76MeHNQ_Gd9t"
      },
      "source": [
        "## Task 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PART II: SMILES\n",
        "- String sequence to continous values\n",
        "- Permutational invariance should be taken into account with canonical SMILES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Lv736iffCez4"
      },
      "outputs": [],
      "source": [
        "# Tokenize the SMILES strings\n",
        "# https://jcheminf.biomedcentral.com/articles/10.1186/s13321-023-00725-9\n",
        "# Unclear to me whether we want to encode to values, but seems logical\n",
        "class SMILESAISTokenizer:\n",
        "    def __init__(self):\n",
        "        self.vocab = set()\n",
        "        self.special_tokens = ['<PAD>', '<SOS>', '<EOS>', '<UNK>']\n",
        "        self.token_to_idx = {}\n",
        "        self.idx_to_token = {}\n",
        "    \n",
        "    def build_vocabulary(self, smiles_list):\n",
        "        tokens = set()\n",
        "\n",
        "        for smi in smiles_list:\n",
        "            tokens.update(self.tokenize(smi))\n",
        "\n",
        "        tokens = sorted(list(tokens))\n",
        "        full_vocab = self.special_tokens + tokens\n",
        "        self.vocab = full_vocab\n",
        "        self.token_to_idx = {tok: i for i, tok in enumerate(full_vocab)}\n",
        "        self.idx_to_token = {i: tok for tok, i in self.token_to_idx.items()}\n",
        "\n",
        "        return full_vocab\n",
        "    \n",
        "    def tokenize(self, smiles):\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is None:\n",
        "            return []\n",
        "\n",
        "        tokens = []\n",
        "        for atom in mol.GetAtoms():\n",
        "            symbol = atom.GetSymbol()\n",
        "            if atom.GetIsAromatic():\n",
        "                symbol = symbol.lower()\n",
        "\n",
        "            charge = atom.GetFormalCharge()\n",
        "            chiral = str(atom.GetChiralTag())\n",
        "            hs = atom.GetTotalNumHs()\n",
        "            ring = 'R' if atom.IsInRing() else '!R'\n",
        "            neighbors = sorted([nbr.GetSymbol() for nbr in atom.GetNeighbors()])\n",
        "\n",
        "            token = f\"{symbol}:{charge}:{chiral}:{hs}:{ring}:[{','.join(neighbors)}]\"\n",
        "            tokens.append(token)\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def encode(self, smiles, max_length=None):\n",
        "        tokens = self.tokenize(smiles)\n",
        "        # Add <SOS> and <EOS> tokens to learn start and end of sequence\n",
        "        tokens = ['<SOS>'] + tokens + ['<EOS>']\n",
        "        encoded = [self.token_to_idx.get(tok, self.token_to_idx['<UNK>']) for tok in tokens]\n",
        "\n",
        "        if max_length:\n",
        "            encoded = encoded[:max_length]\n",
        "            encoded += [self.token_to_idx['<PAD>']] * (max_length - len(encoded))\n",
        "        return encoded\n",
        "\n",
        "    def decode(self, indices):\n",
        "        tokens = [self.idx_to_token.get(idx, '<UNK>') for idx in indices]\n",
        "        tokens = [tok for tok in tokens if tok not in self.special_tokens]\n",
        "        return tokens # Not sure whether we need decoder\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # TOY TEST\n",
        "# smiles_list = [\n",
        "#     \"CCO\",         # ethanol\n",
        "#     \"c1ccccc1\",    # benzene\n",
        "#     \"C[N+](C)(C)C\",# tetramethylammonium\n",
        "#     \"O=C=O\"        # carbon dioxide\n",
        "# ]\n",
        "\n",
        "# tokenizer = SMILESAISTokenizer()\n",
        "# # Initialize and build vocab\n",
        "# vocab = tokenizer.build_vocabulary(smiles_list)\n",
        "# print(\"Vocabulary size:\", len(vocab))\n",
        "\n",
        "# # Tokenize and encode a molecule\n",
        "# encoded = tokenizer.encode(\"CCO\", max_length=10)\n",
        "# print(\"Encoded:\", encoded)\n",
        "# print(\"Decoded tokens:\", tokenizer.decode(encoded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Randomized augmentation: https://pubs.rsc.org/en/content/articlelanding/2022/dd/d2dd00058j\n",
        "class SMILESDataset(Dataset):\n",
        "    def __init__(self, tokenizer, smiles_list, formation_energy, augment=True, max_length=None):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.smiles = smiles_list\n",
        "        self.augment = augment\n",
        "        self.max_length = max_length\n",
        "        self.formation_energy = formation_energy\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.smiles)\n",
        "\n",
        "    def randomize_smiles(self, mol):\n",
        "        return Chem.MolToSmiles(mol, doRandom=True)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        smiles = self.smiles[idx]\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is None:\n",
        "            return self.__getitem__((idx + 1) % len(self.smiles))  # fallback\n",
        "\n",
        "        if self.augment:\n",
        "            smiles = self.randomize_smiles(mol)\n",
        "        else:\n",
        "            smiles = Chem.MolToSmiles(mol, canonical=True)\n",
        "\n",
        "        encoded = self.tokenizer.encode(smiles, max_length=self.max_length)\n",
        "        target = self.formation_energy[idx]\n",
        "        return torch.tensor(encoded, dtype=torch.long), torch.tensor(target, dtype=torch.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create tokenzier and dataset\n",
        "tokenizer = SMILESAISTokenizer()\n",
        "tokenizer.build_vocabulary(smiles_data)\n",
        "max_length = 100 # the  maximum length of SMILES strings is 62, tokenization might change that\n",
        "\n",
        "# Split data into train and validation 80/20, already having a test dataset\n",
        "train_data = [smiles_data[i] for i in train_idxes[:-int(0.2 * len(train_idxes))]] # select first 80% of train_idxes; no overlap measured\n",
        "val_data = [smiles_data[i] for i in train_idxes[-int(0.2 * len(train_idxes)):]] # select last 20% of train_idxes; no overlap measured\n",
        "test_data = [smiles_data[i] for i in test_idxes]\n",
        "\n",
        "train_targets = fe[train_idxes[:-int(0.2 * len(train_idxes))]]\n",
        "val_targets = fe[train_idxes[-int(0.2 * len(train_idxes)):]]\n",
        "test_targets = fe[test_idxes]\n",
        "\n",
        "train_dataset = SMILESDataset(tokenizer, train_data, train_targets, augment=True, max_length=max_length)\n",
        "val_dataset = SMILESDataset(tokenizer, val_data, val_targets, augment=False, max_length=max_length)\n",
        "test_dataset = SMILESDataset(tokenizer, test_data, test_targets, augment=False, max_length=max_length)\n",
        "\n",
        "# batch size could potentially be increased with lots of data\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transformer block\n",
        "# https://pubs.rsc.org/en/content/articlelanding/2022/dd/d2dd00058j\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.attention = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
        "        self.layer_norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(embed_dim, ff_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(ff_dim, embed_dim)\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Multi-head attention with residual connection\n",
        "        attn_output, _ = self.attention(x, x, x)\n",
        "        x = self.layer_norm1(x + self.dropout(attn_output))\n",
        "\n",
        "        # Feed-forward network with residual connection\n",
        "        mlp_output = self.mlp(x)\n",
        "        x = self.layer_norm2(x + self.dropout(mlp_output))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, embed_dim, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, embed_dim)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * (-torch.log(torch.tensor(10000.0)) / embed_dim))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_heads, ff_dim, num_layers, max_len, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.positional_encoding = PositionalEncoding(embed_dim, max_len)\n",
        "        self.transformer_blocks = nn.ModuleList([\n",
        "            TransformerBlock(embed_dim, num_heads, ff_dim, dropout) for _ in range(num_layers)\n",
        "        ])\n",
        "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
        "        self.regression_head = nn.Sequential(\n",
        "            nn.Linear(embed_dim, embed_dim // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(embed_dim // 2, 1)  # Output a single value\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input embedding + positional encoding\n",
        "        x = self.embedding(x)\n",
        "        x = self.positional_encoding(x)\n",
        "\n",
        "        # Pass through Transformer blocks\n",
        "        for block in self.transformer_blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        # Apply LayerNorm and regression head\n",
        "        x = self.layer_norm(x)\n",
        "        x = x.mean(dim=1)  # Global pooling (mean over sequence length); this type of pooling should probably be changed\n",
        "        x = self.regression_head(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 1])\n"
          ]
        }
      ],
      "source": [
        "# Inital guess for parameters\n",
        "vocab_size = len(tokenizer.vocab)  # Vocabulary size from tokenizer\n",
        "embed_dim = 128  # Embedding dimension\n",
        "num_heads = 4  # Number of attention heads; research further the relation between embed dim and heads\n",
        "ff_dim =  512 # Feed-forward network dimension; typically 4 times embedding so 1024\n",
        "num_layers = 6  # Number of Transformer layers\n",
        "max_len = 100  # Maximum sequence length; should be checked based on tokenization\n",
        "\n",
        "model = TransformerDecoder(vocab_size, embed_dim, num_heads, ff_dim, num_layers, max_len)\n",
        "\n",
        "# Example input (batch of tokenized SMILES)\n",
        "input_tokens = torch.randint(0, vocab_size, (32, max_len))  # Batch of 32 sequences\n",
        "output = model(input_tokens)  # Output shape: (32, 1)\n",
        "print(output.shape)  # Should be [32, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code to train the model \n",
        "def train_model(model, train_loader, val_loader, num_epochs=10, learning_rate=1e-3):\n",
        "    model.to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for i, (batch, targets) in enumerate(train_loader):\n",
        "            batch = batch.to(device)\n",
        "            targets = targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch)\n",
        "            loss = criterion(outputs.squeeze(), targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        train_losses.append(avg_loss)\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # Validation step\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for i, (batch, targets) in enumerate(val_loader):\n",
        "                batch = batch.to(device)\n",
        "                targets = targets.to(device)\n",
        "                outputs = model(batch)\n",
        "                loss = criterion(outputs.squeeze(), targets)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        val_losses.append(avg_val_loss)\n",
        "        print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss', marker='o')\n",
        "    plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss', marker='o')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss Curves')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Training Loss: 0.9248\n",
            "Validation Loss: 0.9015\n",
            "Epoch 2/10, Training Loss: 0.8247\n",
            "Validation Loss: 0.8397\n",
            "Epoch 3/10, Training Loss: 0.9253\n",
            "Validation Loss: 0.9855\n",
            "Epoch 4/10, Training Loss: 0.9897\n",
            "Validation Loss: 1.0294\n",
            "Epoch 5/10, Training Loss: 0.8015\n",
            "Validation Loss: 0.3786\n",
            "Epoch 6/10, Training Loss: 0.3553\n",
            "Validation Loss: 0.3452\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[49], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model;learning rate potentially lower is better \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer_decoder.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "Cell \u001b[1;32mIn[47], line 19\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, num_epochs, learning_rate)\u001b[0m\n\u001b[0;32m     17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(batch)\n\u001b[0;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39msqueeze(), targets)\n\u001b[1;32m---> 19\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     21\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
            "File \u001b[1;32mc:\\Users\\20182672\\AppData\\Local\\anaconda3\\envs\\MLEngineering\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\20182672\\AppData\\Local\\anaconda3\\envs\\MLEngineering\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\20182672\\AppData\\Local\\anaconda3\\envs\\MLEngineering\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Train the model;learning rate potentially lower is better \n",
        "train_model(model, train_loader, val_loader, num_epochs=10, learning_rate=1e-4)\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'transformer_decoder.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    criterion = nn.MSELoss()\n",
        "    all_targets = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch, targets in test_loader:\n",
        "            batch = batch.to(device)\n",
        "            targets = targets.to(device)\n",
        "            outputs = model(batch)\n",
        "            loss = criterion(outputs.squeeze(), targets)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Collect predictions and targets for MAE and R²\n",
        "            all_predictions.extend(outputs.squeeze().cpu().numpy())\n",
        "            all_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(test_loader)\n",
        "    mae = mean_absolute_error(all_targets, all_predictions)\n",
        "    r2 = r2_score(all_targets, all_predictions)\n",
        "    apd = np.mean([\n",
        "        np.abs((pred - target) / target) for pred, target in zip(all_predictions, all_targets) if target != 0\n",
        "    ]) # Average Percentage Deviation based on \"Understanding the language of molecules...\" paper\n",
        "\n",
        "    print(f\"Test Loss (MSE): {avg_loss:.4f}\")\n",
        "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "    print(f\"R² Score: {r2:.4f}\")\n",
        "    print(f\"Average Percentage Deviation (APD): {apd:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0zvKnpLGf9v"
      },
      "source": [
        "## Task 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AC1KICrZGgkY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mIuOY4BGxqU"
      },
      "source": [
        "## Task 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_NgxsO3GxEE"
      },
      "outputs": [],
      "source": [
        "def is_valid_smiles(smiles):\n",
        "    if smiles is None:\n",
        "        return False\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        return mol is not None\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "def canonicalize(smiles):\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol:\n",
        "            return Chem.MolToSmiles(mol, canonical=True)\n",
        "        return 'None'\n",
        "    except:\n",
        "        return 'None'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SN_jGgOwG4kK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('COO', 'COO')"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "canonicalize(\"COO\"), canonicalize(\"O(C)O\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bhjYhYrHCuQ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(True, True, False)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "is_valid_smiles(\"COO\"), is_valid_smiles(\"O(C)O\"), is_valid_smiles(\"C##\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_YgzDpMH-Vl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "MLEngineering",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
