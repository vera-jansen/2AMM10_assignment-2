{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wv9q_pcGshE"
      },
      "source": [
        "# Assignment 2 2AMM10 2023-2024\n",
        "\n",
        "## Group: [Fill in your group name]\n",
        "### Member 1: [Fill in your name]\n",
        "### Member 2: [Fill in your name]\n",
        "### Member 3: [Fill in your name]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQzvuDWw_Eyw"
      },
      "source": [
        "We need to install some specific libraries. The cell below installs torch_geometric for torch 2.6.0+cu124. In case the current version of torch is different, check [here](https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html) to see which versions (of both libraries) you should install. You might also need to install an old version of torch from [here](https://pytorch.org/get-started/previous-versions/)\n",
        "\n",
        "**Note:** Do not install pyg_lib from the optional dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibC2lMHfD67H"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-2.7.0-cp310-cp310-win_amd64.whl.metadata (29 kB)\n",
            "Collecting filelock (from torch)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages (from torch) (4.12.2)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in c:\\users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages (from torch) (2025.5.1)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading torch-2.7.0-cp310-cp310-win_amd64.whl (212.5 MB)\n",
            "   ---------------------------------------- 0.0/212.5 MB ? eta -:--:--\n",
            "    --------------------------------------- 4.7/212.5 MB 25.9 MB/s eta 0:00:09\n",
            "   - -------------------------------------- 10.2/212.5 MB 25.5 MB/s eta 0:00:08\n",
            "   -- ------------------------------------- 15.5/212.5 MB 25.6 MB/s eta 0:00:08\n",
            "   --- ------------------------------------ 20.7/212.5 MB 25.2 MB/s eta 0:00:08\n",
            "   ---- ----------------------------------- 26.0/212.5 MB 25.3 MB/s eta 0:00:08\n",
            "   ----- ---------------------------------- 31.5/212.5 MB 25.3 MB/s eta 0:00:08\n",
            "   ------ --------------------------------- 37.0/212.5 MB 25.5 MB/s eta 0:00:07\n",
            "   ------- -------------------------------- 41.9/212.5 MB 25.4 MB/s eta 0:00:07\n",
            "   -------- ------------------------------- 47.4/212.5 MB 25.4 MB/s eta 0:00:07\n",
            "   --------- ------------------------------ 53.0/212.5 MB 25.4 MB/s eta 0:00:07\n",
            "   ----------- ---------------------------- 58.5/212.5 MB 25.3 MB/s eta 0:00:07\n",
            "   ------------ --------------------------- 64.0/212.5 MB 25.5 MB/s eta 0:00:06\n",
            "   ------------ --------------------------- 68.9/212.5 MB 25.4 MB/s eta 0:00:06\n",
            "   -------------- ------------------------- 74.4/212.5 MB 25.4 MB/s eta 0:00:06\n",
            "   --------------- ------------------------ 80.0/212.5 MB 25.4 MB/s eta 0:00:06\n",
            "   ---------------- ----------------------- 85.5/212.5 MB 25.4 MB/s eta 0:00:06\n",
            "   ----------------- ---------------------- 91.0/212.5 MB 25.5 MB/s eta 0:00:05\n",
            "   ------------------ --------------------- 95.9/212.5 MB 25.4 MB/s eta 0:00:05\n",
            "   ------------------ -------------------- 101.2/212.5 MB 25.4 MB/s eta 0:00:05\n",
            "   ------------------- ------------------- 105.6/212.5 MB 25.3 MB/s eta 0:00:05\n",
            "   -------------------- ------------------ 111.1/212.5 MB 25.3 MB/s eta 0:00:05\n",
            "   --------------------- ----------------- 116.1/212.5 MB 25.2 MB/s eta 0:00:04\n",
            "   ---------------------- ---------------- 121.4/212.5 MB 25.2 MB/s eta 0:00:04\n",
            "   ----------------------- --------------- 126.9/212.5 MB 25.2 MB/s eta 0:00:04\n",
            "   ------------------------ -------------- 131.9/212.5 MB 25.3 MB/s eta 0:00:04\n",
            "   ------------------------- ------------- 137.1/212.5 MB 25.3 MB/s eta 0:00:03\n",
            "   -------------------------- ------------ 142.6/212.5 MB 25.3 MB/s eta 0:00:03\n",
            "   --------------------------- ----------- 148.1/212.5 MB 25.3 MB/s eta 0:00:03\n",
            "   ---------------------------- ---------- 153.6/212.5 MB 25.3 MB/s eta 0:00:03\n",
            "   ----------------------------- --------- 159.1/212.5 MB 25.3 MB/s eta 0:00:03\n",
            "   ------------------------------ -------- 164.6/212.5 MB 25.3 MB/s eta 0:00:02\n",
            "   ------------------------------- ------- 169.6/212.5 MB 25.3 MB/s eta 0:00:02\n",
            "   -------------------------------- ------ 174.9/212.5 MB 25.3 MB/s eta 0:00:02\n",
            "   --------------------------------- ----- 180.4/212.5 MB 25.3 MB/s eta 0:00:02\n",
            "   ---------------------------------- ---- 185.9/212.5 MB 25.3 MB/s eta 0:00:02\n",
            "   ----------------------------------- --- 191.1/212.5 MB 25.3 MB/s eta 0:00:01\n",
            "   ------------------------------------ -- 196.6/212.5 MB 25.3 MB/s eta 0:00:01\n",
            "   ------------------------------------- - 202.1/212.5 MB 25.3 MB/s eta 0:00:01\n",
            "   --------------------------------------  207.6/212.5 MB 25.3 MB/s eta 0:00:01\n",
            "   --------------------------------------  212.3/212.5 MB 25.3 MB/s eta 0:00:01\n",
            "   --------------------------------------  212.3/212.5 MB 25.3 MB/s eta 0:00:01\n",
            "   --------------------------------------- 212.5/212.5 MB 24.4 MB/s eta 0:00:00\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
            "   ------------------------------- -------- 5.0/6.3 MB 25.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 6.3/6.3 MB 24.1 MB/s eta 0:00:00\n",
            "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.7/1.7 MB 23.2 MB/s eta 0:00:00\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Installing collected packages: mpmath, sympy, networkx, filelock, torch\n",
            "Successfully installed filelock-3.18.0 mpmath-1.3.0 networkx-3.4.2 sympy-1.14.0 torch-2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip show torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8qrPQFNe_AJu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2025.3.2-cp310-cp310-win_amd64.whl.metadata (4.1 kB)\n",
            "Collecting numpy (from rdkit)\n",
            "  Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
            "Collecting Pillow (from rdkit)\n",
            "  Downloading pillow-11.2.1-cp310-cp310-win_amd64.whl.metadata (9.1 kB)\n",
            "Downloading rdkit-2025.3.2-cp310-cp310-win_amd64.whl (22.7 MB)\n",
            "   ---------------------------------------- 0.0/22.7 MB ? eta -:--:--\n",
            "   ------- -------------------------------- 4.5/22.7 MB 26.7 MB/s eta 0:00:01\n",
            "   ----------------- ---------------------- 10.0/22.7 MB 25.9 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 14.7/22.7 MB 24.9 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 20.2/22.7 MB 25.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 22.7/22.7 MB 24.0 MB/s eta 0:00:00\n",
            "Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
            "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
            "   ---------------- ----------------------- 5.2/12.9 MB 26.5 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 10.7/12.9 MB 25.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 12.9/12.9 MB 23.8 MB/s eta 0:00:00\n",
            "Downloading pillow-11.2.1-cp310-cp310-win_amd64.whl (2.7 MB)\n",
            "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
            "   ---------------------------------------- 2.7/2.7 MB 26.0 MB/s eta 0:00:00\n",
            "Installing collected packages: Pillow, numpy, rdkit\n",
            "Successfully installed Pillow-11.2.1 numpy-2.2.6 rdkit-2025.3.2\n",
            "Collecting torch_geometric\n",
            "  Using cached torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "Collecting aiohttp (from torch_geometric)\n",
            "  Downloading aiohttp-3.12.6-cp310-cp310-win_amd64.whl.metadata (7.9 kB)\n",
            "Collecting fsspec (from torch_geometric)\n",
            "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting jinja2 (from torch_geometric)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: numpy in c:\\users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages (from torch_geometric) (2.2.6)\n",
            "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages (from torch_geometric) (5.9.0)\n",
            "Collecting pyparsing (from torch_geometric)\n",
            "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting requests (from torch_geometric)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tqdm (from torch_geometric)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp->torch_geometric)\n",
            "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp->torch_geometric)\n",
            "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting async-timeout<6.0,>=4.0 (from aiohttp->torch_geometric)\n",
            "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp->torch_geometric)\n",
            "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->torch_geometric)\n",
            "  Downloading frozenlist-1.6.0-cp310-cp310-win_amd64.whl.metadata (16 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->torch_geometric)\n",
            "  Downloading multidict-6.4.4-cp310-cp310-win_amd64.whl.metadata (5.5 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp->torch_geometric)\n",
            "  Downloading propcache-0.3.1-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp->torch_geometric)\n",
            "  Downloading yarl-1.20.0-cp310-cp310-win_amd64.whl.metadata (74 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch_geometric)\n",
            "  Downloading MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl.metadata (4.1 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->torch_geometric)\n",
            "  Downloading charset_normalizer-3.4.2-cp310-cp310-win_amd64.whl.metadata (36 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->torch_geometric)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->torch_geometric)\n",
            "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->torch_geometric)\n",
            "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages (from tqdm->torch_geometric) (0.4.6)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
            "Using cached torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "Downloading aiohttp-3.12.6-cp310-cp310-win_amd64.whl (443 kB)\n",
            "Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
            "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
            "Downloading charset_normalizer-3.4.2-cp310-cp310-win_amd64.whl (105 kB)\n",
            "Downloading frozenlist-1.6.0-cp310-cp310-win_amd64.whl (120 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Downloading MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
            "Downloading multidict-6.4.4-cp310-cp310-win_amd64.whl (38 kB)\n",
            "Downloading propcache-0.3.1-cp310-cp310-win_amd64.whl (45 kB)\n",
            "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "Downloading yarl-1.20.0-cp310-cp310-win_amd64.whl (92 kB)\n",
            "Installing collected packages: urllib3, tqdm, pyparsing, propcache, multidict, MarkupSafe, idna, fsspec, frozenlist, charset-normalizer, certifi, attrs, async-timeout, aiohappyeyeballs, yarl, requests, jinja2, aiosignal, aiohttp, torch_geometric\n",
            "Successfully installed MarkupSafe-3.0.2 aiohappyeyeballs-2.6.1 aiohttp-3.12.6 aiosignal-1.3.2 async-timeout-5.0.1 attrs-25.3.0 certifi-2025.4.26 charset-normalizer-3.4.2 frozenlist-1.6.0 fsspec-2025.5.1 idna-3.10 jinja2-3.1.6 multidict-6.4.4 propcache-0.3.1 pyparsing-3.2.3 requests-2.32.3 torch_geometric-2.6.1 tqdm-4.67.1 urllib3-2.4.0 yarl-1.20.0\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Collecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_scatter-2.1.2%2Bpt26cu124-cp310-cp310-win_amd64.whl (3.5 MB)\n",
            "     ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
            "     ---------------------------------------- 3.5/3.5 MB 22.8 MB/s eta 0:00:00\n",
            "Collecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_sparse-0.6.18%2Bpt26cu124-cp310-cp310-win_amd64.whl (2.1 MB)\n",
            "     ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
            "     ----- ---------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
            "     --------------- ------------------------ 0.8/2.1 MB 3.1 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 1.8/2.1 MB 4.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 2.1/2.1 MB 3.9 MB/s eta 0:00:00\n",
            "Collecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_cluster-1.6.3%2Bpt26cu124-cp310-cp310-win_amd64.whl (1.6 MB)\n",
            "     ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
            "     ---------------------------------------- 1.6/1.6 MB 28.4 MB/s eta 0:00:00\n",
            "Collecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_spline_conv-1.2.2%2Bpt26cu124-cp310-cp310-win_amd64.whl (527 kB)\n",
            "     ---------------------------------------- 0.0/527.4 kB ? eta -:--:--\n",
            "     ------------------------------------- 527.4/527.4 kB 17.7 MB/s eta 0:00:00\n",
            "Collecting scipy (from torch_sparse)\n",
            "  Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in c:\\users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages (from scipy->torch_sparse) (2.2.6)\n",
            "Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl (41.3 MB)\n",
            "   ---------------------------------------- 0.0/41.3 MB ? eta -:--:--\n",
            "   ---- ----------------------------------- 4.7/41.3 MB 23.7 MB/s eta 0:00:02\n",
            "   --------- ------------------------------ 9.7/41.3 MB 25.2 MB/s eta 0:00:02\n",
            "   -------------- ------------------------- 14.7/41.3 MB 24.3 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 20.2/41.3 MB 24.5 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 25.4/41.3 MB 24.8 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 30.7/41.3 MB 25.3 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 36.2/41.3 MB 25.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  41.2/41.3 MB 25.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 41.3/41.3 MB 24.1 MB/s eta 0:00:00\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, scipy, torch_sparse, torch_cluster\n",
            "Successfully installed scipy-1.15.3 torch_cluster-1.6.3+pt26cu124 torch_scatter-2.1.2+pt26cu124 torch_sparse-0.6.18+pt26cu124 torch_spline_conv-1.2.2+pt26cu124\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit\n",
        "!pip install torch_geometric\n",
        "!pip install torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.6.0+cu124.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVL2eo0g_Iuv"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\torch_geometric\\typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: Could not find module 'C:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\Lib\\site-packages\\torch_scatter\\_scatter_cuda.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "c:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\torch_geometric\\typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: Could not find module 'C:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\Lib\\site-packages\\torch_cluster\\_grid_cuda.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
            "c:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\torch_geometric\\typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: Could not find module 'C:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\Lib\\site-packages\\torch_spline_conv\\_basis_cuda.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
            "  warnings.warn(\n",
            "c:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\torch_geometric\\typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: Could not find module 'C:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\Lib\\site-packages\\torch_sparse\\_convert_cuda.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw, AllChem\n",
        "from rdkit import RDLogger\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#added by user\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch import "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "H8rvaK56_iQ7"
      },
      "outputs": [],
      "source": [
        "with open('pos_data.pkl', 'rb') as f:\n",
        "    pos_data = pickle.load(f)\n",
        "\n",
        "with open('type_data.pkl', 'rb') as f:\n",
        "    type_data = pickle.load(f)\n",
        "\n",
        "with open('smiles.pkl', 'rb') as f:\n",
        "    smiles_data = pickle.load(f)\n",
        "\n",
        "data_split = np.load('data_split.npz')\n",
        "\n",
        "train_idxes = data_split['train_idx']\n",
        "test_idxes = data_split['test_idx']\n",
        "\n",
        "formation_energy = np.load('formation_energy.npz')\n",
        "\n",
        "fe = formation_energy['y'] # normalized formation energy\n",
        "mu = formation_energy['mu']\n",
        "std = formation_energy['sigma']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DIsGRQcxA_4Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of data\n",
            "pos_data: 129012, type_data: 129012, smiles: 129012\n",
            "Idxes\n",
            "train: 119012, test: 10000, sum: 129012\n"
          ]
        }
      ],
      "source": [
        "# shapes of lists\n",
        "print(\"Length of data\")\n",
        "print(f\"pos_data: {len(pos_data)}, type_data: {len(type_data)}, smiles: {len(smiles_data)}\")\n",
        "print(\"Idxes\")\n",
        "print(f\"train: {len(train_idxes)}, test: {len(test_idxes)}, sum: {len(train_idxes) + len(test_idxes)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bVDJF7I3BFa2"
      },
      "outputs": [],
      "source": [
        "def at_number_to_atom_name(at_number):\n",
        "    if at_number == 6:\n",
        "        return 'C'\n",
        "    elif at_number == 1:\n",
        "        return 'H'\n",
        "    elif at_number == 7:\n",
        "        return 'N'\n",
        "    elif at_number == 8:\n",
        "        return 'O'\n",
        "    elif at_number == 9:\n",
        "        return 'F'\n",
        "    elif at_number == 16:\n",
        "        return 'S'\n",
        "    else:\n",
        "        return 'Unknown'\n",
        "\n",
        "def inspect_structure(idx):\n",
        "    smile = smiles_data[idx]\n",
        "    pos = pos_data[idx]\n",
        "    typ = type_data[idx]\n",
        "\n",
        "    header = f\"{'Atom':^5}│{'Number':^6}│{'x':^10}│{'y':^10}│{'z':^10}\"\n",
        "    line   = \"─────┼──────┼──────────┼──────────┼──────────\"\n",
        "    print(header)\n",
        "    print(line)\n",
        "\n",
        "    for atom_num, (x, y, z) in zip(typ, pos):\n",
        "        atom_sym = at_number_to_atom_name(atom_num)\n",
        "        print(f\"{atom_sym:^5}│{atom_num:^6}│{x:>10.3f}│{y:>10.3f}│{z:>10.3f}\")\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "    print(f'SMILE: {smile}')\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "    print(f'Formation Energy: {fe[idx]*std + mu:.3f}')\n",
        "    print(f'Formation Energy (normalized): {fe[idx]:.5f}')\n",
        "    mol = Chem.MolFromSmiles(smile)\n",
        "    if mol:\n",
        "        # RDKit prefers 2‑D coordinates for nice depictions\n",
        "        Chem.AllChem.Compute2DCoords(mol)\n",
        "        img = Draw.MolToImage(mol, size=(300, 300))\n",
        "\n",
        "        # Display with matplotlib (works both in notebooks and scripts)\n",
        "        plt.figure(figsize=(3, 3))\n",
        "        plt.axis('off')\n",
        "        plt.imshow(img)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "K1rs7hhCC4oq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Atom │Number│    x     │    y     │    z     \n",
            "─────┼──────┼──────────┼──────────┼──────────\n",
            "  C  │  6   │    -0.013│     1.086│     0.008\n",
            "  H  │  1   │     0.002│    -0.006│     0.002\n",
            "  H  │  1   │     1.012│     1.464│     0.000\n",
            "  H  │  1   │    -0.541│     1.447│    -0.877\n",
            "  H  │  1   │    -0.524│     1.438│     0.906\n",
            "\n",
            "\n",
            "SMILE: C\n",
            "\n",
            "\n",
            "Formation Energy: -17.172\n",
            "Formation Energy (normalized): 5.72327\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# methane\n",
        "# Note how methane has a relatively high formation energy (compared to QM9)\n",
        "# This correlates with lower thermodynamic stability and higher reactivity\n",
        "# For example, methane readily burns in oxygen (CH₄ + 2O₂ → CO₂ + 2H₂O)\n",
        "inspect_structure(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vo8hYLuQCeBR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Atom │Number│    x     │    y     │    z     \n",
            "─────┼──────┼──────────┼──────────┼──────────\n",
            "  N  │  7   │     0.278│     0.426│     1.305\n",
            "  C  │  6   │     0.078│    -0.002│     0.129\n",
            "  O  │  8   │     1.055│     0.207│    -0.839\n",
            "  C  │  6   │     1.396│    -0.628│    -1.874\n",
            "  O  │  8   │     2.177│    -0.227│    -2.687\n",
            "  C  │  6   │     0.771│    -2.003│    -1.889\n",
            "  C  │  6   │    -0.713│    -1.961│    -2.280\n",
            "  C  │  6   │    -1.601│    -1.320│    -1.257\n",
            "  C  │  6   │    -1.242│    -0.543│    -0.232\n",
            "  H  │  1   │     1.219│     0.816│     1.385\n",
            "  H  │  1   │     1.337│    -2.590│    -2.614\n",
            "  H  │  1   │     0.875│    -2.471│    -0.904\n",
            "  H  │  1   │    -0.833│    -1.464│    -3.253\n",
            "  H  │  1   │    -1.059│    -2.990│    -2.437\n",
            "  H  │  1   │    -2.658│    -1.562│    -1.345\n",
            "  H  │  1   │    -1.995│    -0.237│     0.487\n",
            "\n",
            "\n",
            "SMILE: [NH-]C1=C[CH-]CCC(=O)O1\n",
            "\n",
            "\n",
            "Formation Energy: -71.789\n",
            "Formation Energy (normalized): 0.42631\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# random structure\n",
        "inspect_structure(np.random.choice(range(len(smiles_data))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76MeHNQ_Gd9t"
      },
      "source": [
        "## Task 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lv736iffCez4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def build_edges_molecule(positions, cutoff):\n",
        "    \"\"\"\n",
        "    Given a single molecule's atom positions (Nx3 tensor or list of N 3D coords),\n",
        "    returns edge_index suitable for SchNet input.\n",
        "    \"\"\"\n",
        "    if not isinstance(positions, torch.Tensor):\n",
        "        positions = torch.tensor(positions, dtype=torch.float32)\n",
        "\n",
        "    num_atoms = positions.size(0)\n",
        "    list_from = []\n",
        "    list_to = []\n",
        "\n",
        "    for i in range(num_atoms):\n",
        "        for j in range(num_atoms):\n",
        "            if i == j:\n",
        "                continue\n",
        "            dist = torch.norm(positions[i] - positions[j])\n",
        "            if dist <= cutoff:\n",
        "                list_from.append(i)\n",
        "                list_to.append(j)\n",
        "\n",
        "    edge_index = torch.tensor([list_from, list_to], dtype=torch.long)\n",
        "    return edge_index\n",
        "\n",
        "def build_edges_all(pos_data, cutoff):\n",
        "    \"\"\"\n",
        "    Build edge indices for all molecules in pos_data\n",
        "    \"\"\"\n",
        "    edge_indices = []\n",
        "\n",
        "    for molecule in pos_data:\n",
        "        edge_index = build_edges_molecule(molecule, cutoff=cutoff)\n",
        "        edge_indices.append(edge_index)\n",
        "\n",
        "    return edge_indices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "#edge_indices = build_edges_all(pos_data, cutoff=1.5)\n",
        "\n",
        "# Save\n",
        "#torch.save(edge_indices, \"edges.pt\")\n",
        "\n",
        "# Load\n",
        "edge_indices = torch.load(\"edges.pt\")\n",
        "\n",
        "pos_data = [torch.tensor(mol, dtype=torch.float32) for mol in pos_data]\n",
        "type_data = [torch.tensor(mol, dtype=torch.long) for mol in type_data]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "class MoleculeDataset(Dataset):\n",
        "    def __init__(self, pos_data, type_data, edge_indices, formation_energy, indices):\n",
        "        self.pos_data = pos_data\n",
        "        self.type_data = type_data\n",
        "        self.edge_indices = edge_indices\n",
        "        self.formation_energy = formation_energy\n",
        "        self.indices = indices\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        i = self.indices[idx]\n",
        "        return (\n",
        "            self.type_data[i], \n",
        "            self.pos_data[i],   \n",
        "            self.edge_indices[i],\n",
        "            self.formation_energy[i]\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "class RBFExpansion(nn.Module):\n",
        "    \"\"\"\n",
        "    Radial Basis Function Expansion is a way to transform distances\n",
        "    into a set of features that can be used in neural networks.\n",
        "    This uses a Gaussian RBF, like in SchNet.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_rbf=32, cutoff=1.5, gamma=10.0):\n",
        "        super().__init__()\n",
        "        centers = torch.linspace(0, cutoff, num_rbf) #create RBF centers, creates 32 values from 0 to cutoff\n",
        "        self.register_buffer('centers', centers) #for GPU compatibility\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, distances):\n",
        "        return torch.exp(-self.gamma * (distances.unsqueeze(1) - self.centers) ** 2)\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, hidden_dim=64, layers=2):\n",
        "        super().__init__()\n",
        "        net = []\n",
        "        dims = [in_dim] + [hidden_dim] * (layers - 1) + [out_dim]\n",
        "        for i in range(len(dims) - 1):\n",
        "            net.append(nn.Linear(dims[i], dims[i + 1]))\n",
        "            if i < len(dims) - 2:\n",
        "                net.append(nn.SiLU())\n",
        "        self.model = nn.Sequential(*net)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# --- Interaction Block ---\n",
        "class InteractionBlock(nn.Module):\n",
        "    def __init__(self, hidden_dim, num_rbf):\n",
        "        super().__init__()\n",
        "        self.filter_net = MLP(num_rbf, hidden_dim)\n",
        "        self.dense = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.update_net = MLP(hidden_dim, hidden_dim)\n",
        "\n",
        "    def forward(self, h, edge_index, rbf):\n",
        "        row, col = edge_index\n",
        "        f_ij = self.filter_net(rbf)\n",
        "        m_ij = f_ij * h[col]\n",
        "        agg = torch.zeros_like(h)\n",
        "        agg.index_add_(0, row, m_ij)\n",
        "        return h + self.update_net(self.dense(agg))\n",
        "\n",
        "# --- SchNet as LightningModule ---\n",
        "class SchNetLightning(pl.LightningModule):\n",
        "    def __init__(self, num_atom_types, hidden_dim=64, num_rbf=32, num_blocks=3, lr=1e-3):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.embedding = nn.Embedding(num_atom_types, hidden_dim)\n",
        "        self.rbf_layer = RBFExpansion(num_rbf)\n",
        "        self.interaction_blocks = nn.ModuleList([\n",
        "            InteractionBlock(hidden_dim, num_rbf) for _ in range(num_blocks)\n",
        "        ])\n",
        "        self.readout = MLP(hidden_dim, 1)\n",
        "        self.lr = lr\n",
        "\n",
        "    def forward(self, atom_types, positions, edge_index):\n",
        "        h = self.embedding(atom_types)\n",
        "        row, col = edge_index\n",
        "        distances = torch.norm(positions[row] - positions[col], dim=1)\n",
        "        rbf = self.rbf_layer(distances)\n",
        "\n",
        "        for block in self.interaction_blocks:\n",
        "            h = block(h, edge_index, rbf)\n",
        "\n",
        "        atom_energies = self.readout(h).squeeze(-1)\n",
        "        return atom_energies.sum()\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        atom_types_list, positions_list, edge_indices_list, targets = batch\n",
        "        pred_energies = []\n",
        "\n",
        "        for atom_types, pos, edge_idx in zip(atom_types_list, positions_list, edge_indices_list):\n",
        "            energy = self(atom_types, pos, edge_idx)\n",
        "            pred_energies.append(energy)\n",
        "            \n",
        "        pred = torch.stack(pred_energies)\n",
        "        loss = F.mse_loss(pred, targets)\n",
        "        self.log(\"train_loss\", loss, batch_size= batch_size)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        atom_types_list, positions_list, edge_indices_list, targets = batch\n",
        "\n",
        "        pred_energies = []\n",
        "        for atom_types, pos, edge_idx in zip(atom_types_list, positions_list, edge_indices_list):\n",
        "            energy = self(atom_types, pos, edge_idx)\n",
        "            pred_energies.append(energy)\n",
        "\n",
        "        pred = torch.stack(pred_energies)\n",
        "        loss = F.mse_loss(pred, targets)\n",
        "        self.log(\"val_loss\", loss, batch_size= batch_size)\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def custom_collate(batch):\n",
        "    atom_types, positions, edge_indices, targets = zip(*batch)\n",
        "    return (\n",
        "        list(atom_types),\n",
        "        list(positions),\n",
        "        list(edge_indices),\n",
        "        torch.tensor([float(t) for t in targets], dtype=torch.float32)\n",
        "    )\n",
        "\n",
        "train_idx, val_idx = train_test_split(train_idxes, test_size=0.2, random_state=0)\n",
        "batch_size = 32\n",
        "\n",
        "train_dataset = MoleculeDataset(pos_data, type_data, edge_indices, fe, train_idx)\n",
        "val_dataset   = MoleculeDataset(pos_data, type_data, edge_indices, fe, val_idx)\n",
        "test_dataset  = MoleculeDataset(pos_data, type_data, edge_indices, fe, test_idxes)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name               | Type         | Params | Mode \n",
            "------------------------------------------------------------\n",
            "0 | embedding          | Embedding    | 640    | train\n",
            "1 | rbf_layer          | RBFExpansion | 0      | train\n",
            "2 | interaction_blocks | ModuleList   | 56.3 K | train\n",
            "3 | readout            | MLP          | 4.2 K  | train\n",
            "------------------------------------------------------------\n",
            "61.1 K    Trainable params\n",
            "0         Non-trainable params\n",
            "61.1 K    Total params\n",
            "0.244     Total estimated model params size (MB)\n",
            "44        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                           "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:   4%|▍         | 123/2976 [00:08<03:21, 14.14it/s, v_num=12]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'exit' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:599\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    593\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    595\u001b[0m     ckpt_path,\n\u001b[0;32m    596\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    597\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    598\u001b[0m )\n\u001b[1;32m--> 599\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1012\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m-> 1012\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1056\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:216\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:455\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:150\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:320\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[1;32m--> 320\u001b[0m     batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:192\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[1;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:270\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[1;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[1;32m--> 270\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:176\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[1;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\pytorch_lightning\\core\\module.py:1302\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[1;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;124;03mthe optimizer.\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1300\u001b[0m \n\u001b[0;32m   1301\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1302\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\pytorch_lightning\\core\\optimizer.py:154\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[1;34m(self, closure, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 154\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy\u001b[38;5;241m.\u001b[39moptimizer_step(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer, closure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:239\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[1;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[1;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39moptimizer_step(optimizer, model\u001b[38;5;241m=\u001b[39mmodel, closure\u001b[38;5;241m=\u001b[39mclosure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision.py:123\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[1;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[1;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m optimizer\u001b[38;5;241m.\u001b[39mstep(closure\u001b[38;5;241m=\u001b[39mclosure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\torch\\optim\\optimizer.py:485\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    481\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    482\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    483\u001b[0m             )\n\u001b[1;32m--> 485\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\torch\\optim\\optimizer.py:79\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 79\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\torch\\optim\\adam.py:225\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m--> 225\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision.py:109\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[1;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03mhook is called.\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m \n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:146\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclosure(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:131\u001b[0m, in \u001b[0;36mClosure.closure\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39menable_grad()\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[1;32m--> 131\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:319\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[1;32m--> 319\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:328\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 328\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:391\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mtraining_step(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "Cell \u001b[1;32mIn[169], line 79\u001b[0m, in \u001b[0;36mSchNetLightning.training_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m     78\u001b[0m atom_types_list, positions_list, edge_indices_list, targets \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m---> 79\u001b[0m pred_energies \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m(atom_types, pos, edge_idx)\n\u001b[0;32m     80\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m atom_types, pos, edge_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(atom_types_list, positions_list, edge_indices_list)]\n\u001b[0;32m     81\u001b[0m pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(pred_energies)\n",
            "Cell \u001b[1;32mIn[169], line 79\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     78\u001b[0m atom_types_list, positions_list, edge_indices_list, targets \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m---> 79\u001b[0m pred_energies \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43matom_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m atom_types, pos, edge_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(atom_types_list, positions_list, edge_indices_list)]\n\u001b[0;32m     81\u001b[0m pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(pred_energies)\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[169], line 71\u001b[0m, in \u001b[0;36mSchNetLightning.forward\u001b[1;34m(self, atom_types, positions, edge_index)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minteraction_blocks:\n\u001b[1;32m---> 71\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrbf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m atom_energies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreadout(h)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[169], line 48\u001b[0m, in \u001b[0;36mInteractionBlock.forward\u001b[1;34m(self, h, edge_index, rbf)\u001b[0m\n\u001b[0;32m     47\u001b[0m agg\u001b[38;5;241m.\u001b[39mindex_add_(\u001b[38;5;241m0\u001b[39m, row, m_ij)\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m h \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_net(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43magg\u001b[49m\u001b[43m)\u001b[49m)\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[173], line 18\u001b[0m\n\u001b[0;32m     11\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     12\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     13\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m,       \u001b[38;5;66;03m# or 'gpu'\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[early_stop_callback],\n\u001b[0;32m     15\u001b[0m     enable_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;66;03m# shows loss after each epoch\u001b[39;00m\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m SchNetLightning(num_atom_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:561\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 561\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\veraj\\anaconda3\\envs\\mlcourse\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:65\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[0;32m     64\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[1;32m---> 65\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[0;32m     68\u001b[0m     _interrupt(trainer, exception)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'exit' is not defined"
          ]
        }
      ],
      "source": [
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "\n",
        "early_stop_callback = EarlyStopping(\n",
        "    monitor='val_loss',      # metric to monitor\n",
        "    patience=5,              # epochs to wait for improvement\n",
        "    verbose=True,\n",
        "    mode='min'               # minimize the val_loss\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    max_epochs=50,\n",
        "    accelerator='cpu',       # or 'gpu'\n",
        "    callbacks=[early_stop_callback],\n",
        "    enable_progress_bar=True # shows loss after each epoch\n",
        ")\n",
        "model = SchNetLightning(num_atom_types=10)\n",
        "trainer.fit(model, train_loader, val_loader)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test MSE loss: 0.1922\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "test_losses = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        atom_types_list, positions_list, edge_indices_list, targets = batch\n",
        "        preds = []\n",
        "        for atom_types, pos, edge_idx in zip(atom_types_list, positions_list, edge_indices_list):\n",
        "            pred = model(atom_types, pos, edge_idx)\n",
        "            preds.append(pred)\n",
        "        preds = torch.stack([pred if isinstance(pred, torch.Tensor) else torch.tensor(pred) for pred in preds])\n",
        "        loss = F.mse_loss(preds, targets)\n",
        "        test_losses.append(loss.item())\n",
        "\n",
        "mean_test_loss = sum(test_losses) / len(test_losses)\n",
        "print(f\"Test MSE loss: {mean_test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example: if you already have fe as a NumPy array\n",
        "# fe = np.array([...])  # Your actual formation energy values\n",
        "\n",
        "# Plot the histogram\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.hist(fe, bins=20, color='skyblue', edgecolor='black')\n",
        "plt.title('Histogram of Formation Energy (fe)')\n",
        "plt.xlabel('Formation Energy')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0zvKnpLGf9v"
      },
      "source": [
        "## Task 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mIuOY4BGxqU"
      },
      "source": [
        "## Task 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_NgxsO3GxEE"
      },
      "outputs": [],
      "source": [
        "def is_valid_smiles(smiles):\n",
        "    if smiles is None:\n",
        "        return False\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        return mol is not None\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "def canonicalize(smiles):\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol:\n",
        "            return Chem.MolToSmiles(mol, canonical=True)\n",
        "        return 'None'\n",
        "    except:\n",
        "        return 'None'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SN_jGgOwG4kK"
      },
      "outputs": [],
      "source": [
        "canonicalize(\"COO\"), canonicalize(\"O(C)O\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bhjYhYrHCuQ"
      },
      "outputs": [],
      "source": [
        "is_valid_smiles(\"COO\"), is_valid_smiles(\"O(C)O\"), is_valid_smiles(\"C##\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_YgzDpMH-Vl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mlcourse",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
